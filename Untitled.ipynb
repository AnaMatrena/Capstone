{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236d8af3-ec3c-4c23-9871-002e2c620f91",
   "metadata": {},
   "source": [
    "# Scikit model in a flask app on railway\n",
    "Don't understand a word of this heading? Let's translate.\n",
    "\n",
    "So far, you've learned to set up scikit-learn models in Jupyter notebooks. But if you work for a client, how are they going to use your model? Surely they don't want to learn Python to get their predictions.\n",
    "\n",
    "Here is where flask apps come into play. [Flask](https://flask.palletsprojects.com/en/stable/) is a web application framework. It allows you to create an application which will nicely package your model into a box. The client will insert an observation and the application will return the prediction for it.\n",
    "\n",
    "Now this application has to run somewhere. It could be on an internal company server, but it could also be hosted on a cloud. [Railway](https://railway.com/) offers infrastructure to run web applications and also provides databases where you can store the data - the observations and the predictions.\n",
    "\n",
    "<img src=\"media/480px-Cloud9_Superstore_Logo.jpeg\" width=\"300\">\n",
    "\n",
    "## 0. tl;dr\n",
    "\n",
    "You can deploy your own model by\n",
    "\n",
    "1. Copying the contents of this repo to a new directory\n",
    "1. Replace `pipeline.pickle`, `dtypes.pickle`, and `columns.json` with\n",
    "   your own\n",
    "1. [Deploy to railway](#deploy-to-railway)\n",
    "\n",
    "You'll probably run into a few issues along the way which is why you'll at least want to\n",
    "skim the contents of the notebooks and this README, in order to have an idea of\n",
    "where to look when you hit a bump in the road.\n",
    "\n",
    "## 1. Intro\n",
    "\n",
    "This is a very simplistic yet effective way to deploy a scikit model behind a HTTP server on railway.\n",
    "\n",
    "There are 4 main topics to cover here:\n",
    "\n",
    "1. Serialization\n",
    "    - This is covered in the notebooks\n",
    "1. Flask\n",
    "    - Covered here in the README\n",
    "1. Database connection\n",
    "    - Covered here in the README\n",
    "1. Deployment to railway\n",
    "    - Also covered here in the README\n",
    "\n",
    "### 1.1 Before you continue\n",
    "\n",
    "Topic #1 is the only one that is not covered here in this README. It is covered in two notebooks\n",
    "that you must read before moving on with the rest of this README.\n",
    "\n",
    "[Notebook #1](Learning notebook - Part 1 of 2 - Train and serialize.ipynb) has to do with training and serializing a scikit model as well as how to prepare a new observation that arrives for prediction.\n",
    "\n",
    "[Notebook #2](Learning notebook - Part 2 of 2 - Deserialize and use.ipynb) explains how to deserialize the saved model so that you can use a trained model with new observations without having to re-train it.\n",
    "\n",
    "### 1.2 Python virtual environment\n",
    "\n",
    "You've probably noticed that we have two requirement files in this repo: `requirements_dev.txt` and `requirements_prod.txt`.\n",
    "\n",
    "The `requirements_dev.txt` file has the packages that are needed while preparing the model and include jupyter and matplotlib.\n",
    "\n",
    "The `requirements_prod.txt` file has the packages that are needed when we deploy our model. At that point, we won't need jupyter or matplotlib, so we can save some resources by not installing them.\n",
    "\n",
    "Now go ahead and create a Python virtual env using the requirements in `requirements_dev.txt` in order to follow this tutorial.\n",
    "\n",
    "## 2. Flask\n",
    "\n",
    "Have you already read and understood the notebooks on serialization? Have you already tested your understanding\n",
    "by pickling and un-pickling your scikit model? Yes yes? Alrighty then, you may continue.\n",
    "\n",
    "### 2.1 What is flask\n",
    "\n",
    "[Flask](https://flask.palletsprojects.com/en/stable/) is an HTTP micro-framework. It is a very minimal code library that allows\n",
    "for quick and simple HTTP server development and is a great alternative to bigger frameworks like Django.\n",
    "However, be wary before moving forward with a big project using flask - it can get out of hand very quickly\n",
    "without the enforced structure that other heavier frameworks like Django provide.\n",
    "\n",
    "For us, since we only need a total of two endpoints (an endpoint is the URL that is used to request an action from the server; in our case we will need two types of actions: requesting a prediction for an observation, and updating an observation's true class) and it doesn't even need to be [RESTful](https://en.wikipedia.org/wiki/Representational_state_transfer), we can stick with\n",
    "flask and be reasonably justified in it.\n",
    "\n",
    "### 2.2 Create an HTTP server\n",
    "\n",
    "In order to use flask, you will need to write code in a regular\n",
    "Python file - no more notebooks here.\n",
    "\n",
    "The first step (assuming you have already created a virtual environment and installed the requirements in requirements_dev.txt), is to import flask at the top of the file and create the HTTP server. Let's pretend that we are working in a file called app.py in our newly created virtual environment.\n",
    "\n",
    "We're doing three imports. The [Flask](https://flask.palletsprojects.com/en/stable/api/#application-object) object is for creating an HTTP server. The [request](https://flask.palletsprojects.com/en/stable/api/#flask.request) object does exactly what the name suggests: holds all of the contents of an HTTP request that someone is making. The [jsonify](https://flask.palletsprojects.com/en/stable/api/#flask.json.jsonify) function converts objects such as dictionaries to json.\n",
    "\n",
    "Next we use the Flask constructor to create a new application. We will add routes to it later.\n",
    "\n",
    "```py\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "```\n",
    "\n",
    "This server doesn't do anything yet. In order to make it do stuff we will\n",
    "need to add HTTP endpoints.\n",
    "\n",
    "### 2.3 Make HTTP endpoints\n",
    "\n",
    "With flask, creating an HTTP endpoint is incredibly simple, assuming that we already\n",
    "have the `app` object created with the `Flask` constructor. Let's make an endpoint that will serve the predictions:\n",
    "\n",
    "```py\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    prediction = 0.5\n",
    "    return jsonify({\n",
    "        'prediction': prediction\n",
    "    })\n",
    "```\n",
    "\n",
    "The above route isn't very smart in that it returns the same\n",
    "prediction every time (0.5) and it doesn't actually care about the input\n",
    "that you sent it. But hey, with just a few lines of code we've almost created an entire server that serves a prediction!\n",
    "\n",
    "### 2.4 Make a complete server\n",
    "\n",
    "Putting it all together with a few lines of code at the end (in order to start\n",
    "the server in development mode), we've created an entire server.\n",
    "\n",
    "```py\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    prediction = 0.5\n",
    "    return jsonify({\n",
    "        'prediction': prediction\n",
    "    })\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "\n",
    "```\n",
    "\n",
    "Create a new file called `first_app.py` and save the above code. To run the server, open a terminal window and create a new virtual environment for production with the `requirements_prod.txt` file. Then run the server by executing `python3.12 first_app.py. You're server will now be running locally.\n",
    "\n",
    "Now you can send requests to your server and get predictions. Open a new terminal window, activate the production virtual environment, and execute the following command in order to get a prediction:\n",
    "\n",
    "```bash\n",
    "~ > curl -X POST http://localhost:5000/predict\n",
    "```\n",
    "\n",
    "You should get the following output:\n",
    "```\n",
    "{\n",
    "  \"prediction\": 0.5\n",
    "}\n",
    "```\n",
    "\n",
    "We are using the [curl](https://curl.se/) library here to transfer data to our local server.\n",
    "\n",
    "Alright, now that we can run a full flask server, let's try to make something a bit more\n",
    "useful - a server that can receive data.\n",
    "\n",
    "### 2.5 Receive a new observation\n",
    "\n",
    "Let's set up the server so that it can receive information from us. There's a pretty nice way to do this via the\n",
    "[get_json](https://flask.palletsprojects.com/en/stable/api/#flask.Response.get_json) flask function.\n",
    "\n",
    "For this server, let's say that the model only takes a single field called `unemployed`\n",
    "and returns `true` if `unemployed` is true and `false` otherwise. The server would now\n",
    "look like this:\n",
    "\n",
    "```py\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    payload = request.get_json()\n",
    "    at_risk = payload['unemployed']\n",
    "    return jsonify({\n",
    "        'prediction': at_risk\n",
    "    })\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "```\n",
    "Add this code to your `first_app.py` file. You can notice that the server has automatically restarted when you made changes to the app file (unless you made a syntax error in which case it shut down). Now test the server with the following examples:\n",
    "```bash\n",
    "~ > curl -X POST http://localhost:5000/predict -d '{\"unemployed\": true}' -H \"Content-Type:application/json\"\n",
    "```\n",
    "\n",
    "You should get:\n",
    "```\n",
    "{\n",
    "  \"prediction\": true\n",
    "}\n",
    "```\n",
    "\n",
    "For this command:\n",
    "```bash\n",
    "~ > curl -X POST http://localhost:5000/predict -d '{\"unemployed\": false}' -H \"Content-Type:application/json\"\n",
    "```\n",
    "\n",
    "You should get:\n",
    "```\n",
    "{\n",
    "  \"prediction\": false\n",
    "}\n",
    "```\n",
    "\n",
    "Take a quick note that we had to supply a header of `Content-Type:application/json`\n",
    "and json data of `{\"unemployed\": false}`.\n",
    "\n",
    "### 2.6 Integrate a scikit model\n",
    "\n",
    "Now that we know how to get a Python dictionary via the flask `get_json`\n",
    "function, we're at a point in which we can pick up where the last tutorial\n",
    "notebook left off! We will insert the pickled model into the app and make it receive new observations and return predictions. Let's tie it all together by:\n",
    "\n",
    "1. Deserializing the model, columns, and dtypes\n",
    "1. Turn the new observation into a pandas dataframe\n",
    "1. Call `predict_proba` to get the likelihood of survival of the new observation\n",
    "\n",
    "```py\n",
    "import joblib\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "with open('columns.json') as fh:\n",
    "    columns = json.load(fh)\n",
    "\n",
    "with open('dtypes.pickle', 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "\n",
    "pipeline = joblib.load('pipeline.pickle')\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    payload = request.get_json()\n",
    "    obs = pd.DataFrame([payload], columns=columns).astype(dtypes)\n",
    "    proba = pipeline.predict_proba(obs)[0, 1]\n",
    "    return jsonify({\n",
    "        'prediction': proba\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "```\n",
    "\n",
    "Check out how we have now taken the payload and turned it into\n",
    "a new observation that is a single entry in a dataframe,\n",
    "and can be consumed by the pipeline to be turned into a prediction\n",
    "of survival. Copy the code into your app file and test it with the following:\n",
    "\n",
    "```\n",
    "~ >  curl -X POST http://localhost:5000/predict -d '{\"Age\": 22.0, \"Cabin\": null, \"Embarked\": \"S\", \"Fare\": 7.25, \"Parch\": 0, \"Pclass\": 3, \"Sex\": \"male\", \"SibSp\": 1}' -H \"Content-Type:application/json\"\n",
    "```\n",
    "\n",
    "You should get:\n",
    "```\n",
    "{\n",
    "  \"prediction\": 0.16097398111735517\n",
    "}\n",
    "```\n",
    "\n",
    "## 3. Keeping track of your predictions\n",
    "\n",
    "Okay, now that you can get data, produce predictions, and return those predictions,\n",
    "you will need to keep track of what you've been saying about who.\n",
    "Said another way: you can't just provide predictions and then just forget about it all. You need to\n",
    "take record of what you have predicted about which input, so that later on you can do some additional analysis on your \"through the door\" population.\n",
    "\n",
    "In order to do this, we will need to start working with a database. The database\n",
    "will keep track of the observations, the predictions that the model provided for them,\n",
    "and the true outcomes (should we be luckly enough to find out about them).\n",
    "\n",
    "### 3.1 ORMs and peewee\n",
    "\n",
    "When working with databases in code, you generally want to be using a layer of abstraction\n",
    "called an [ORM](https://en.wikipedia.org/wiki/Object-relational_mapping). For this\n",
    "exercise we will use a very simplistic ORM called [peewee](http://docs.peewee-orm.com/en/latest/index.html).\n",
    "This will allow us to use a local database called [sqlite](https://en.wikipedia.org/wiki/SQLite) (which is basically a file)\n",
    "when we are developing on our laptops, and use a more production-ready database called\n",
    "[postgresql](https://en.wikipedia.org/wiki/PostgreSQL) when deploying to railway, with very\n",
    "little change to our code.\n",
    "\n",
    "One cool thing that ORMs allow us to do is define the data model that we want\n",
    "to use in code. So let's use peewee to create a data model to keep track of\n",
    "predictions and the probabilities we have assigned to them. Once again, we can\n",
    "take care of this with a few lines of code:\n",
    "\n",
    "```py\n",
    "from peewee import (\n",
    "    SqliteDatabase, Model, IntegerField,\n",
    "    FloatField, TextField,\n",
    ")\n",
    "\n",
    "DB = SqliteDatabase('predictions.db')\n",
    "\n",
    "class Prediction(Model):\n",
    "    observation_id = IntegerField(unique=True)\n",
    "    observation = TextField()\n",
    "    proba = FloatField()\n",
    "    true_class = IntegerField(null=True)\n",
    "\n",
    "    class Meta:\n",
    "        database = DB\n",
    "\n",
    "DB.create_tables([Prediction], safe=True)\n",
    "```\n",
    "\n",
    "Now we need to take a moment to understand exactly how much these\n",
    "few lines of code have done for us because it is A LOT.\n",
    "\n",
    "#### 3.1.1 Connect to database\n",
    "\n",
    "`DB = SqliteDatabase('predictions.db')`\n",
    "\n",
    "Create an sqlite database that will be stored in a file called `predictions.db`.\n",
    "This may seem trivial right now, but soon enough you will see that changing\n",
    "out this line of code for another one will result in a lot of value for the effort.\n",
    "\n",
    "#### 3.1.2 Define the data model\n",
    "\n",
    "```\n",
    "Class Prediction(Model):\n",
    "   ...\n",
    "```   \n",
    "\n",
    "Define the data model that we will work with, so basically the fields in the database table. The model has fields for\n",
    "the following:\n",
    "\n",
    "- `observation_id`\n",
    "    - There must be a unique identifier to all observations and it is\n",
    "      the responsibility of the person providing the observation to give\n",
    "      this id.\n",
    "- `observation`\n",
    "    - We should record the observation itself when it comes, in case\n",
    "      we want to retrain our model with it later on.\n",
    "- `proba`\n",
    "    - The probability of survival that we predicted for the observation.\n",
    "- `true_class`\n",
    "    - This is for later on, in case we find out what is the true value of the target for the observation for which we supplied a prediction.\n",
    "\n",
    "#### 3.1.3 Create the table\n",
    "\n",
    "`DB.create_tables([Prediction], safe=True)`\n",
    "\n",
    "The model that we specified must correspond to a database table.\n",
    "Creation of these tables is something that is it's own non-trivial\n",
    "headache, and this one line of code makes it so that we don't have to worry about any of it.\n",
    "\n",
    "## 4. Integrate the database with the webserver\n",
    "\n",
    "Now that we have a webserver and a database that we are happy with, the next question is how do we put them together? It's actually pretty straightforward!\n",
    "\n",
    "```py\n",
    "import joblib\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, jsonify, request\n",
    "from peewee import (\n",
    "    SqliteDatabase, PostgresqlDatabase, Model, IntegerField,\n",
    "    FloatField, TextField, IntegrityError\n",
    ")\n",
    "from playhouse.shortcuts import model_to_dict\n",
    "\n",
    "\n",
    "########################################\n",
    "# Begin database stuff\n",
    "\n",
    "DB = SqliteDatabase('predictions.db')\n",
    "\n",
    "\n",
    "class Prediction(Model):\n",
    "    observation_id = IntegerField(unique=True)\n",
    "    observation = TextField()\n",
    "    proba = FloatField()\n",
    "    true_class = IntegerField(null=True)\n",
    "\n",
    "    class Meta:\n",
    "        database = DB\n",
    "\n",
    "\n",
    "DB.create_tables([Prediction], safe=True)\n",
    "\n",
    "# End database stuff\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# Unpickle the previously-trained model\n",
    "\n",
    "\n",
    "with open('columns.json') as fh:\n",
    "    columns = json.load(fh)\n",
    "\n",
    "\n",
    "with open('dtypes.pickle', 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "\n",
    "\n",
    "pipeline = joblib.load('pipeline.pickle')\n",
    "\n",
    "\n",
    "# End model un-pickling\n",
    "########################################\n",
    "\n",
    "\n",
    "########################################\n",
    "# Begin webserver stuff\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    obs_dict = request.get_json()\n",
    "    _id = obs_dict['id']\n",
    "    observation = obs_dict['observation']\n",
    "    obs = pd.DataFrame([observation], columns=columns).astype(dtypes)\n",
    "    proba = pipeline.predict_proba(obs)[0, 1]\n",
    "    response = {'proba': proba}\n",
    "    p = Prediction(\n",
    "        observation_id=_id,\n",
    "        proba=proba,\n",
    "        observation=request.data\n",
    "    )\n",
    "    try:\n",
    "        p.save()\n",
    "    except IntegrityError:\n",
    "        error_msg = \"ERROR: Observation ID: '{}' already exists\".format(_id)\n",
    "        response[\"error\"] = error_msg\n",
    "        print(error_msg)\n",
    "        DB.rollback()\n",
    "    return jsonify(response)\n",
    "\n",
    "\n",
    "# End webserver stuff\n",
    "########################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "\n",
    "```\n",
    "\n",
    "One piece of the code above that might not be clear at first is:\n",
    "\n",
    "```py\n",
    "    p = Prediction(\n",
    "        observation_id=_id,\n",
    "        proba=proba,\n",
    "        observation=request.data,\n",
    "    )\n",
    "    try:\n",
    "        p.save()\n",
    "    except IntegrityError:\n",
    "        error_msg = \"ERROR: Observation ID: '{}' already exists\".format(_id)\n",
    "        response[\"error\"] = error_msg\n",
    "        print(error_msg)\n",
    "        DB.rollback()\n",
    "```\n",
    "\n",
    "What is this code doing? When we receive a new prediction request, we want to store such request\n",
    "in our database (to keep track of our model performance). With peewee, we save a new Prediction (basically\n",
    "a new row in our table) with the `save()` method, which is very neat and convenient.\n",
    "\n",
    "However, because our table has a unique constraint (no two rows can have the same `observation_id`, which is a unique field),\n",
    "if we perform the same prediction request twice (with the same id) the system will crash because pewee can't save\n",
    "again an already saved observation_id, it will throw an `IntegrityError` (as in, we would be asking pewee to violate\n",
    "the integrity of the table's unique id requirement if we saved a duplicated id, right?).\n",
    "\n",
    "To avoid that, we do a simple try/except block: if we try a request with the same observation_id, peewee will raise the integrity error and we'll catch it, print a nice error message, and do a database rollback (to close the current save transaction that has failed).\n",
    "\n",
    "Once your app is setup like this, you can test this with the following command:\n",
    "\n",
    "```bash\n",
    "~ > curl -X POST http://localhost:5000/predict -d '{\"id\": 0, \"observation\": {\"Age\": 22.0, \"Cabin\": null, \"Embarked\": \"S\", \"Fare\": 7.25, \"Parch\": 0, \"Pclass\": 3, \"Sex\": \"male\", \"SibSp\": 1}}' -H \"Content-Type:application/json\"\n",
    "```\n",
    "\n",
    "You should get:\n",
    "```\n",
    "{\n",
    "  \"proba\": 0.16097398111735517\n",
    "}\n",
    "```\n",
    "\n",
    "Now let's take note of the few things that changed:\n",
    "\n",
    "1. The structure of the json input changed. It now includes two top level entries:\n",
    "    - `id` - This is the unique identifier of the observation;\n",
    "    - `observation` - This is the actual observation contents that will be sent to\n",
    "      the pipeline we have un-pickled.\n",
    "1. We create an instance of `Prediction` with the 3 fields that we care about.\n",
    "1. We call `save()` on the prediction to save it to the database.\n",
    "1. We return `proba` so that the caller of the HTTP endpoint knows what the model\n",
    "says about the observation.\n",
    "\n",
    "## 5. Receiving updates\n",
    "\n",
    "Now that we have a way to provide predictions AND keep track of them, we should\n",
    "take it to the next level and provide ourselves with a way to receive updates\n",
    "on the true class of the observations that we have judged with our predictive model.\n",
    "\n",
    "We can do this with one extra `update` endpoint that is very straightforward and only\n",
    "introduces one new concept: database querying through the ORM.\n",
    "\n",
    "```py\n",
    "@app.route('/update', methods=['POST'])\n",
    "def update():\n",
    "    obs = request.get_json()\n",
    "    try:\n",
    "        p = Prediction.get(Prediction.observation_id == obs['id'])\n",
    "        p.true_class = obs['true_class']\n",
    "        p.save()\n",
    "        return jsonify(model_to_dict(p))\n",
    "    except Prediction.DoesNotExist:\n",
    "        error_msg = 'Observation ID: \"{}\" does not exist'.format(obs['id'])\n",
    "        return jsonify({'error': error_msg})\n",
    "```\n",
    "\n",
    "Assuming that we have already processed an observation with id=0, we\n",
    "can now receive and record the true outcome. Imagine that it is discovered\n",
    "later on that the person with id=0 didn't survive the Titanic disaster. They\n",
    "would probably enter something into a content management system that\n",
    "would then trigger a call to your server which would end up looking like\n",
    "the following:\n",
    "\n",
    "```bash\n",
    "~ > curl -X POST http://localhost:5000/update -d '{\"id\": 0, \"true_class\": 0}'  -H \"Content-Type:application/json\"\n",
    "```\n",
    "\n",
    "And it would elicit a response from your server like:\n",
    "```\n",
    "{\n",
    "  \"id\": 1,\n",
    "  \"observation\": \"{\\\"id\\\": 0, \\\"observation\\\": {\\\"Age\\\": 22.0, \\\"Cabin\\\": null, \\\"Embarked\\\": \\\"S\\\", \\\"Fare\\\": 7.25, \\\"Parch\\\": 0, \\\"Pclass\\\": 3, \\\"Sex\\\": \\\"male\\\", \\\"SibSp\\\": 1}}\",\n",
    "  \"observation_id\": 0,\n",
    "  \"proba\": 0.16097398111735517,\n",
    "  \"true_class\": 0\n",
    "}\n",
    "```\n",
    "\n",
    "Similarly to when we saved the prediction requests, we validate that the observation_id we want to update actually exists.\n",
    "\n",
    "Now to wrap it all up, the way that we can interpret this sequence of events is the following:\n",
    "\n",
    "1. We provided a prediction of 0.161 probability of survival;\n",
    "1. We found out later that the person didn't survive.\n",
    "\n",
    "\n",
    "## 6. Deploy to railway\n",
    "\n",
    "It's cool and all that we can run the servers on our own machines. However, it doesn't\n",
    "do much good in terms of making the model available to the rest of the world. All this\n",
    "`localhost` stuff doesn't help anybody who's not at your local machine.\n",
    "\n",
    "So let's take all of the work we've done getting this running and put it on a cloud where it can generate real business value. For this part, you can use any server\n",
    "that has a static IP address though since we want to avoid the overhead of administering\n",
    "our own server, we will use a service to do this for us called [railway](https://railway.app/).\n",
    "Railway includes a free-tier that should be enough for our needs throughout this specialization and the whole capstone project, but **only if you remember to turn off your applications once you're done with them**. You have a **$5.00** of credit and **it's your responsibility to manage this**. Be careful before you move forward with a big project on railway -\n",
    "it can get CRAZY expensive REALLY fast.\n",
    "\n",
    "### 6.1 Set up your repo\n",
    "Railway will deploy your code from a GitHub repo, so first you need to make a copy of this repository and make sure that your app code is in the `app.py` file.\n",
    "\n",
    "### 6.2 Sign up and set up at railway\n",
    "\n",
    "Go to the [railway main page](https://railway.app/) and start a new project deployed from a github repo. Alternatively you can use the login button.\n",
    "\n",
    "![main page](media/main_page.png)\n",
    "![gh deploy](media/gh_deploy.png)\n",
    "\n",
    "Sign in using your GitHub credentials and verify your account.\n",
    "\n",
    "![gh login](media/gh_login.png)\n",
    "\n",
    "Once this is all done, go to the [dashboard](https://railway.app/dashboard) and create a new\n",
    "app:\n",
    "\n",
    "![create new app](media/new_project.png)\n",
    "\n",
    "Then on the next screen, we'll reselect the \"deploy from GitHub\" option. Grant access to your repositories and select the appropriate one. Afterwards click on \"Deploy now\". \n",
    "\n",
    "![select project from github](media/new_project_2.png)\n",
    "![deploy project](media/new_project_3.png)\n",
    "\n",
    "Once this is done, you'll be taken to the main dashboard where you'll see your application building. Wait until it's completed, signaled by a green box saying \"Success\". **In this tab we can see a button that will allow us to check the logs of our app.** This will be very important to check whether our app is responding successfully to the requests sent or not.\n",
    "\n",
    "![success build](media/build_successful.png)\n",
    "\n",
    "Go to \"Settings\" and scroll down to \"Generate Domain\". Click on the \"Generate domain\" button. **This will generate a url for your app, and we can use it to make requests to your app.**\n",
    "\n",
    "![generate domain](media/generate_domain.png)\n",
    "![generate domain example](media/generate_domain_2.png)\n",
    "\n",
    "One last thing before we can move on to the database creation, we need to redefine what port our requests will be coming from. As seen above, we're using `port 5000`. We can define this by going to the \"Variables\" tab, and add a new `PORT` variable with this value.\n",
    "\n",
    "![port variable](media/port.png)\n",
    "\n",
    "### 6.3 Database \n",
    "\n",
    "One last bit is missing here: **the database**. We are going to use a big boy database\n",
    "called postgreSQL. You should try to be conservative with how you connect to the app and don't go crazy with it. If the database gets full your app will stop working!\n",
    "\n",
    "You can check railway's postgreSQL guide [here](https://docs.railway.app/databases/postgresql).\n",
    "\n",
    "To add a Database to our app, go to the dashboard, right click and select a new service to add:\n",
    "\n",
    "![start database](media/database+from_dashboard.png)\n",
    "\n",
    "The database should automatically connect to your app. Go to \"Variables\" and check that you have the `DATABASE_URL` variable define:\n",
    "![connect database variable](media/database_connect_variable.png)\n",
    "\n",
    "Wait for the app to redeploy after adding the database and test that the app is connected to the database like this:\n",
    "\n",
    "![connect database query](media/database_connect_query.png)\n",
    "\n",
    "There is no data in the table, but it exists because the query ran successfully.\n",
    "\n",
    "### 6.4 Remove deployment\n",
    "\n",
    "To stop billing and resource usage, you'll need to stop the application from running. To do so, find your app and database in the dashboard and select the 3 dots in the most recent deployment. Select \"Remove\". \n",
    "\n",
    "![remove deployment](media/remove_deployment.png)\n",
    "![remove deployment 2](media/remove_deployment_2.png)\n",
    "\n",
    "It is very important to do this everytime you stop working with the app, otherwise you can run out of credit!\n",
    "\n",
    "### 6.5 Final remarks\n",
    "\n",
    "We have now successfully deployed our app **IN THE CLOUD, WAAAT?!?!**\n",
    "It is important to remember that any changes you make to your app locally need to be transfered to the repository (add, commit) to be deployed. So if you change your pipeline and retrain a different model you'll need to commit the changes before\n",
    "rebuilding in railway.\n",
    "\n",
    "And boom! We're done and deployed! You can actually see this working by executing some of the curl commands that we saw before but using the URL we've obtained before from railway, rather than `http://localhost` like earlier. For my app it looks like the following:\n",
    "\n",
    " ```bash\n",
    "curl -X POST https://<given_url>/predict -d '{\"id\": 0, \"observation\": {\"Age\": 22.0, \"Cabin\": NaN, \"Embarked\": \"S\", \"Fare\": 7.25, \"Parch\": 0, \"Pclass\": 3, \"Sex\": \"male\", \"SibSp\": 1}}' -H \"Content-Type:application/json\"\n",
    "```\n",
    "Output:\n",
    "```bash\n",
    "{\n",
    "  \"proba\": 0.09194812456330213\n",
    "}\n",
    " ```\n",
    "\n",
    " And we can receive updates like the following:\n",
    "\n",
    " ```bash\n",
    "curl -X POST https://<given_url>/update -d '{\"id\": 0, \"true_class\": 1}' -H \"Content-Type:application/json\"\n",
    "```\n",
    "\n",
    "Output:\n",
    "```bash\n",
    "{\n",
    "  \"id\": 1,\n",
    "  \"observation\": \"{\\\"id\\\": 0, \\\"observation\\\": {\\\"Age\\\": 22.0, \\\"Cabin\\\": NaN, \\\"Embarked\\\": \\\"S\\\", \\\"Fare\\\": 7.25, \\\"Parch\\\": 0, \\\"Pclass\\\": 3, \\\"Sex\\\": \\\"male\\\", \\\"SibSp\\\": 1}}\",\n",
    "  \"observation_id\": 0,\n",
    "  \"proba\": 0.09194812\n",
    "  \"true_class\": 1\n",
    "}\n",
    "```\n",
    "\n",
    "How does all of this work you ask? Well, it has to do with the fact that there exists a `Dockerfile` in this repo. This file defines the environment in which the app runs. Just be sure that this file is in your repo and that all is committed before you build your app in railway, and everything should work. If you do a deploy and it doesn't work, take a look at the files and see if you might have done something such as change a filename or something else that would break the boilerplate assumptions that we've made here.\n",
    "\n",
    "### 6.6 Import problems\n",
    "\n",
    "If you are using something like a custom transformer and get an import error having to do with your custom code\n",
    "when unpickling, you'll need to do the following.\n",
    "\n",
    "#### 6.6.1 Put your custom code in a package\n",
    "\n",
    "Let's say that you have a custom transformer, called `MyCustomTransformer`, that is part of your\n",
    "pickled pipeline. In that case, you'll want to create a [Python package](https://www.learnpython.org/en/Modules_and_Packages)\n",
    "from which you import the custom transformer in both your training and deployment code.\n",
    "\n",
    "In our example, let's create the following package called `custom_transformers` by just creating a directory\n",
    "with the same name and putting two files inside of it so that it looks like this:\n",
    "\n",
    "```bash\n",
    "└── custom_transformers\n",
    "    ├── __init__.py\n",
    "    └── transformer.py\n",
    "```\n",
    "\n",
    "And inside of `transformer.py` you can put the code for `MyCustomTransformer`. Then, in your training code, you can import them with:\n",
    "\n",
    "```py\n",
    "from custom_transformers.transformer import MyCustomTransformer\n",
    "```\n",
    "\n",
    "When you unpickle your model, Python should be able to find the custom transformer too.\n",
    "\n",
    "The dependencies of your custom transformer should be added to the two `requirements.txt` files.\n",
    "\n",
    "### 6.7 Last few notes\n",
    "\n",
    "There were a few additional changes to `app.py` and the rest of the repo that we haven't covered yet, so\n",
    "let's get that out of the way. You probably won't need to know much about them but if you are having\n",
    "troubleshooting issues, knowing the following may come in handy.\n",
    "\n",
    "#### 6.7.1 The db connector\n",
    "\n",
    "When our app is running on railway, we want to connect to a postgres database, rather than to an sqlite one.\n",
    "Thus, we had to change the database-related code to something that takes care of this:\n",
    "\n",
    "```py\n",
    "import os\n",
    "from playhouse.db_url import connect\n",
    "\n",
    "DB = connect(os.environ.get('DATABASE_URL') or 'sqlite:///predictions.db')\n",
    "```\n",
    "\n",
    "The connect function checks if there is a DATABASE_URL environment variable. If it exists, it is used to connect to a remote postgres db. Otherwise, the function connects to a local sqlite db stored in the predictions.db file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ba5f5-c633-40bd-ad03-6a264ff38b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
